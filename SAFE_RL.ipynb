{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAFE_RL for Highway, Roundabout and Pong Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 15:04:01.843895: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-18 15:04:01.894543: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "from stable_baselines3 import DQN,A2C,SAC,DDPG,PPO\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "import random\n",
    "import pandas as pd\n",
    "from tkinter import Y\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from tqdm import trange\n",
    "from torch.optim import Adam, SGD\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import clear_output\n",
    "# import matplotlib \n",
    "# matplotlib.use(\"Qt5Agg\")\n",
    "# from matplotlib import pyplot as plt\n",
    "import highway_env\n",
    "# from matplotlib import pyplot as plt\n",
    "from scipy.signal import convolve, gaussian\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "import glob\n",
    "from IPython.display import HTML\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from itertools import count\n",
    "from time import time, strftime, localtime\n",
    "import scipy.optimize\n",
    "from tensorboardX import SummaryWriter\n",
    "from core.models import *\n",
    "from core.agent_ray_pd import AgentCollection\n",
    "# import ray\n",
    "# import envs\n",
    "# from trpo import trpo\n",
    "import pickle\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "import argparse\n",
    "# from policy_distillation import main as policy_distillation \n",
    "# from student import Student\n",
    "# from teacher import Teacher\n",
    "from utils.utils import *\n",
    "import util_highway as highway_pkg\n",
    "import util_pong as pong_pkg\n",
    "# from util_highway import create_img_dataset, save_student_model,CF_generation,load_student_model,load_teacher,\\\n",
    "#     student_model_play, compute_class_weight,check_validity, high_dimention_env_train,train_teacher, teacher_model_play\n",
    "from src.star_gan.main import basemodels\n",
    "from src.star_gan.data_loader import get_loader#,solver,model,main\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \",device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters for each models:\n",
    "- set CF_method to SAFE_RL_attGAN(for SAFE-RL), Olson(for Olson model) and GANterfactual(for Huber model)\n",
    "- set mode to test (for extracting metrics) or train \n",
    "- set  (d_lambda_cls, g_lambda_cls, lambda_rec_x, lambda_rec_sal, lambda_gp, lambda_counter, lambda_sal_fuse, g_loss_cls_of_d) to:\n",
    "        (1,1,10,0,10,0,Ture) for GANterfactual model and (0,1,10,10,0,5,False) for SAFE_RL_attGAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "def get_PDCF_config():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--device', type=str, default=device,\n",
    "                        help='set the device (cpu or cuda)')\n",
    "    #environment \n",
    "    parser.add_argument('--env', type=str, default='roundabout', help='highway, roundabout')\n",
    "    parser.add_argument('--env_name', type=str, default='roundabout-v0', help='highway-fast-v0, roundabout-v0')\n",
    "    parser.add_argument('--num_Of_agents', type=int, default=6, help='1 for pong, num_Of_vehicles_Under_vision for highway which is 6')\n",
    "    parser.add_argument('--num_Of_attributes', type=int, default=4, help='4 for pong, vehicle_attr for highway which is 4')\n",
    "    parser.add_argument('--num_of_actions', type=int, default=5, help='6 for pong, 5 for highway')\n",
    "    parser.add_argument('--num_of_stack', type=int, default=4, help='observation history size')\n",
    "    parser.add_argument('--obs_size', type=int, default= (448, 448), help='(84,84) for pong, (512, 128) for highway, (448,448) for roundabout')\n",
    "    parser.add_argument('--image_size', type=int, default=(448, 448), help='(210,160) for pong, (512, 128) for highway, (448,448) for roundabout')\n",
    "    parser.add_argument('--scaling', type=int, default=5, help='5 for highway, 5 for roundabout')\n",
    "    parser.add_argument('--centering_position', type=int, default=[0.5, 0.85], help='[0.2, 0.5] for highway, [0.5, 0.85] for roundabout')\n",
    "    parser.add_argument('--batch_size', type=int, default=8, help='mini-batch size')\n",
    "\n",
    "    # Network, env, MDP, seed\n",
    "    parser.add_argument('--hidden-size', type=int, default=256,\n",
    "                        help='number of hidden units per layer')  \n",
    "    parser.add_argument('--env_input_size', type=int, \n",
    "                        default=parser.parse_args().num_Of_attributes, #+ num_Of_agents*num_of_actions,\n",
    "                        # default=parser.parse_args().num_Of_agents*parser.parse_args().num_Of_attributes, #+ num_Of_agents*num_of_actions,\n",
    "                            help='number of hidden units per layer')\n",
    "    parser.add_argument('--env_output_size', type=int, \n",
    "                        default=parser.parse_args().num_of_actions,\n",
    "                            help='number of hidden units per layer')\n",
    "    parser.add_argument('--num-layers', type=int, default=2,\n",
    "                        help='number of hidden layers')\n",
    "    parser.add_argument('--gamma', type=float, default=0.995, metavar='G',\n",
    "                        help='discount factor (default: 0.995)')\n",
    "    parser.add_argument('--tau', type=float, default=0.97, metavar='G',\n",
    "                        help='gae (default: 0.97)')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='N',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--load-models', default=True, action='store_true',\n",
    "                        help='load_pretrained_models')\n",
    "\n",
    "    # Teacher policy training\n",
    "    parser.add_argument('--teacher_alg', type=str, default='PPO', help='PPO, ')\n",
    "    parser.add_argument('--teacher_models_dir', type=str, default='teacher_models/',)\n",
    "    parser.add_argument('--agent-count', type=int, default=10, metavar='N',\n",
    "                        help='number of agents (default: 100)')\n",
    "    parser.add_argument('--num-teachers', type=int, default=1, metavar='N',\n",
    "                        help='number of teacher policies (default: 1)')\n",
    "    parser.add_argument('--max-kl', type=float, default=1e-2, metavar='G',\n",
    "                        help='max kl value (default: 1e-2)')\n",
    "    parser.add_argument('--cg-damping', type=float, default=1e-2, metavar='G',\n",
    "                        help='damping for conjugate gradient (default: 1e-2)')\n",
    "    parser.add_argument('--cg-iter', type=int, default=10, metavar='G',\n",
    "                        help='maximum iteration of conjugate gradient (default: 1e-1)')\n",
    "    parser.add_argument('--l2-reg', type=float, default=1e-3, metavar='G',\n",
    "                        help='l2 regularization parameter for critics (default: 1e-3)')\n",
    "    parser.add_argument('--teacher-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='per-iteration batch size for each agent (default: 1000)')\n",
    "    parser.add_argument('--sample-batch-size', type=int, default=10000, metavar='N',\n",
    "                        help='expert batch size for each teacher (default: 10000)')\n",
    "    parser.add_argument('--render', action='store_true',\n",
    "                        help='render the environment')\n",
    "    parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n",
    "                        help='interval between training status logs (default: 10)')\n",
    "    parser.add_argument('--num-workers', type=int, default=60,\n",
    "                        help='number of workers for parallel computing')\n",
    "    parser.add_argument('--num-teacher-episodes', type=int, default=10, metavar='N',\n",
    "                        help='num of teacher training episodes (default: 100)')\n",
    "\n",
    "    # Student policy training\n",
    "    parser.add_argument('--student_models_dir', type=str, default='student_models/',)\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, metavar='G',\n",
    "                        help='adam learnig rate (default: 1e-3)')\n",
    "    parser.add_argument('--test-interval', type=int, default=10, metavar='N',\n",
    "                        help='interval between training status logs (default: 10)')\n",
    "    parser.add_argument('--student-batch-size', type=int, default=128, metavar='N',\n",
    "                        help='per-iteration batch size for student (default: 1000)')\n",
    "    parser.add_argument('--batch-type', type=str, default='random',\n",
    "                        help='batch should be selected random or respectively')\n",
    "    parser.add_argument('--sample-interval', type=int, default=10, metavar='N',\n",
    "                        help='frequency to update expert data (default: 10)')\n",
    "    parser.add_argument('--testing-batch-size', type=int, default=512, metavar='N',\n",
    "                        help='batch size for testing student policy (default: 10000)')\n",
    "    parser.add_argument('--num-student-episodes', type=int, default=5, metavar='N',\n",
    "                        help='num of student training episodes (default: 1000)')\n",
    "    parser.add_argument('--report_step', type=int, default=500, metavar='N')\n",
    "    parser.add_argument('--loss-metric', type=str, default='kl',\n",
    "                        help='metric to build student objective, nll, wasserstein or kl or kl_cross or probabilistic')\n",
    "    parser.add_argument('--temperature', type=float, default=0.9,\n",
    "                        help='KL temperature')\n",
    "    parser.add_argument('--betta', type=float, default=0.7,\n",
    "                        help='beta*kl loss + (1-betta)*cross loss')\n",
    "    parser.add_argument('--algo', type=str, default='sgd',\n",
    "                        help='update method')\n",
    "    parser.add_argument('--storm-interval', type=int, default=10, metavar='N',\n",
    "                        help='frequency of storm (default: 10)')\n",
    "    parser.add_argument('--init-alpha', type=float, default=1.0, metavar='G',\n",
    "                        help='storm init alpha (default: 1.0)')\n",
    "    parser.add_argument('--optimizer', type=str, default='ADAM', metavar='G',\n",
    "                        help='student network otimizer, SGD or ADAM')\n",
    "    # counterfactual setting\n",
    "    parser.add_argument('--CF_method', type=str, default='SAFE_RL_attGAN', help='PDCF, SAFE_RL_starGAN, SAFE_RL_attGAN, Olson, GANterfactual')\n",
    "    parser.add_argument('--dataset_dir', type=str, default=\"dataset\", help='saving image of environments for olson and GANterfactual models')\n",
    "    parser.add_argument('--mode', type=str, default=\"train\", help='train, test')\n",
    "    parser.add_argument('--saliency_method', type=str, default=\"EigenCAM\", \\\n",
    "        help='HiResCAM, AblationCAM, ScoreCAM, LayerCAM, FullGradDeep, FeatureFactorization, EigenCAM')\n",
    "    parser.add_argument('--saliency_dim', type=int, default=1, \\\n",
    "        help='1 EigenCAM, c_dim for GradCAM')\n",
    "    parser.add_argument('--wandb_log', type=bool, default=False, help='Weight and bias')\n",
    "\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args \n",
    "\n",
    "def get_Olson_config(PDCF_config):\n",
    "    print('Parsing arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch_size', type=int, default=PDCF_config.batch_size)\n",
    "    parser.add_argument('--epsilon', type=float, default=.2)\n",
    "    parser.add_argument('--lr', type=float, default=15e-4)\n",
    "    # Output directory of the model that creates counterfactual states\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default=\\\n",
    "        os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"models\"))\n",
    "    parser.add_argument('--epochs', type=int, default=300)\n",
    "\n",
    "    parser.add_argument('--latent', type=int, default=16)#16 #64\n",
    "    parser.add_argument('--wae_latent', type=int, default=128)\n",
    "    parser.add_argument('--agent_latent', type=int, default=512)\n",
    "    parser.add_argument('--seed', type=int, default=13)\n",
    "    parser.add_argument('--env', type=str, default=PDCF_config.env)\n",
    "    # Directory of the used wasserstein encoder\n",
    "    parser.add_argument('--Q', type=str, default=\"../../res/models/PacMan_FearGhost2_3_Olson_wae/Q\")\n",
    "    parser.add_argument('--P', type=str, default=\"../../res/models/PacMan_FearGhost2_3_Olson_wae/P\")\n",
    "    parser.add_argument('--missing', type=str, default=\"none\")\n",
    "    # Directory of the RL-Agent that should be explained\n",
    "    parser.add_argument('--agent_file', type=str, default=\"../../res/agents/ACER_PacMan_FearGhost2_cropped_5actions_40M_3.pt\")\n",
    "    parser.add_argument('--enc_lam', type=float, default=5)\n",
    "    parser.add_argument('--clip', type=float, default=.0001)\n",
    "    parser.add_argument('--gen_lam', type=float, default=.5)\n",
    "    parser.add_argument('--starting_epoch', type=int, default=0)\n",
    "    parser.add_argument('--info', type=str, default=\"\")\n",
    "    parser.add_argument('--cf_loss', type=str, default=\"None\")\n",
    "    parser.add_argument('--m_frames', type=int, default=40)\n",
    "    parser.add_argument('--fskip', type=int, default=4)\n",
    "    parser.add_argument('--use_agent', type=int, default=1)\n",
    "    parser.add_argument('--gpu', type=int, default=0)\n",
    "\n",
    "    parser.add_argument('--use_dataset', type=bool, default=True)\n",
    "    # The dataset used for training the model\n",
    "    parser.add_argument('--dataset_dir', type=str, default=\"../../res/datasets/ACER_PacMan_FearGhost2_cropped_5actions_40M_3_Unique\")\n",
    "    parser.add_argument('--img_size', type=str, default=PDCF_config.image_size)\n",
    "    parser.add_argument('--img_channels', type=int, default=3)\n",
    "    parser.add_argument('--action_size', type=int, default=PDCF_config.num_of_actions)\n",
    "    parser.add_argument('--is_pacman', type=bool, default=True)\n",
    "    # Directories.\n",
    "    parser.add_argument('--log_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"logs\"))\n",
    "    parser.add_argument('--model_save_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"models\"))\n",
    "    parser.add_argument('--sample_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"samples\"))\n",
    "    parser.add_argument('--result_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"results\"))\n",
    "    parser.add_argument('--device', type=str, default=PDCF_config.device)\n",
    "    parser.add_argument('--wandb_log', type=bool, default=PDCF_config.wandb_log, help='Weight and bias')\n",
    "    parser.add_argument('--agent_algo', type=str, default=PDCF_config.teacher_alg, help='DQN, PPO, A2C')\n",
    "    parser.add_argument('--mode', type=str, default=PDCF_config.mode, help='train, test')\n",
    "    parser.add_argument('--metrics', default=[\"KID\", \"FID\", \"LPIPS\", \"IS\", \"sparsity\", \"mean_dis\", \"validity\"], help='test model from this step')\n",
    "    parser.add_argument('--load_epoch', type=int, default=None)#train from scratch: None, load best for test: 39, train from the best last experiment: 20\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_starGAN_config(PDCF_config):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Model configuration.\n",
    "    parser.add_argument('--c_dim', type=int, default=PDCF_config.num_of_actions, help='dimension of domain labels (1st dataset)')\n",
    "    parser.add_argument('--c2_dim', type=int, default=PDCF_config.num_of_actions, help='dimension of domain labels (2nd dataset)')\n",
    "    parser.add_argument('--celeba_crop_size', type=int, default=178, help='crop size for the CelebA dataset')\n",
    "    parser.add_argument('--rafd_crop_size', type=int, default=256, help='crop size for the RaFD dataset')\n",
    "    parser.add_argument('--image_size', type=int, default=PDCF_config.image_size[0], help='image resolution')\n",
    "    parser.add_argument('--g_conv_dim', type=int, default=64, help='number of conv filters in the first layer of G')\n",
    "    parser.add_argument('--d_conv_dim', type=int, default=64, help='number of conv filters in the first layer of D')\n",
    "    parser.add_argument('--g_repeat_num', type=int, default=6, help='number of residual blocks in G')\n",
    "    parser.add_argument('--d_repeat_num', type=int, default=6, help='number of strided conv layers in D')\n",
    "    parser.add_argument('--d_lambda_cls', type=float, default=1, help='weight for domain classification loss')\n",
    "    parser.add_argument('--g_lambda_cls', type=float, default=1, help='weight for domain classification loss')\n",
    "    parser.add_argument('--lambda_rec_x', type=float, default=10, help='weight for reconstruction loss of image and obs')\n",
    "    parser.add_argument('--lambda_rec_sal', type=float, default=10, help='weight for reconstruction loss of saliency map')\n",
    "    parser.add_argument('--lambda_gp', type=float, default=10, help='weight for gradient penalty')\n",
    "    parser.add_argument('--lambda_counter', type=float, default=0, help='weight for counter loss')\n",
    "    parser.add_argument('--lambda_sal_fuse', type=float, default=5, help='weight for counter loss')\n",
    "    \n",
    "    parser.add_argument('--g_loss_cls_of_d', type=bool, default=False, help='')\n",
    "\n",
    "    # Training configuration.\n",
    "    parser.add_argument('--dataset', type=str, default=PDCF_config.env, choices=['CelebA', 'RaFD', 'Both'])\n",
    "    parser.add_argument('--batch_size', type=int, default=PDCF_config.batch_size, help='mini-batch size')\n",
    "    parser.add_argument('--num_iters', type=int, default=400000, help='number of total iterations for training D')\n",
    "    parser.add_argument('--num_iters_decay', type=int, default=100000, help='number of iterations for decaying lr')\n",
    "    parser.add_argument('--g_lr', type=float, default=0.0001, help='learning rate for G')\n",
    "    parser.add_argument('--d_lr', type=float, default=0.0001, help='learning rate for D')\n",
    "    parser.add_argument('--n_critic', type=int, default=5, help='number of D updates per each G update')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "    parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "    parser.add_argument('--resume_iters', type=int, default=None, help='resume training from this step')\n",
    "    \n",
    "    # Test configuration.\n",
    "    parser.add_argument('--test_iters', type=int, default=200000, help='test model from this step')\n",
    "    parser.add_argument('--metrics', default=[\"KID\", \"FID\", \"LPIPS\", \"IS\", \"sparsity\", \"mean_dis\", \"validity\"], help='test model from this step')\n",
    "\n",
    "    # Miscellaneous.\n",
    "    parser.add_argument('--num_workers', type=int, default=PDCF_config.num_workers)\n",
    "    parser.add_argument('--mode', type=str, default=PDCF_config.mode)\n",
    "    # Directories.\n",
    "    parser.add_argument('--log_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"logs\"))\n",
    "    parser.add_argument('--model_save_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"models\"))\n",
    "    parser.add_argument('--sample_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"samples\"))\n",
    "    parser.add_argument('--result_dir', type=str, default=os.path.join(\"baseline\", PDCF_config.CF_method, PDCF_config.env, PDCF_config.teacher_alg, \"results\"))\n",
    "\n",
    "    # Step size.\n",
    "    parser.add_argument('--log_step', type=int, default=10)\n",
    "    parser.add_argument('--sample_step', type=int, default=1000)\n",
    "    parser.add_argument('--model_save_step', type=int, default=20000)\n",
    "    parser.add_argument('--lr_update_step', type=int, default=1000)\n",
    "\n",
    "    # Extensions\n",
    "    parser.add_argument('--image_channels', type=int, default=3, help='number of channels of each image')\n",
    "    parser.add_argument('--agent_path', type=str, default=None, help='path to a h5 file containing a rl agent')\n",
    "    parser.add_argument('--counter_mode', type=str, default='cross_entropy', help='whether to use \"raw\",\"cross_entropy\", \"softmax\",'\n",
    "                                                                              '\"advantage\", or \"z-score\"')\n",
    "    parser.add_argument('--selective_counter', type=bool, default=False, help='whether to only use samples where'\n",
    "                                                                             'c_trg != c_org for counter-loss')\n",
    "    # if PDCF_config.CF_method == \"GANterfactual\":\n",
    "    #     parser.add_argument('--agent_type', type=str, default=\"acer\", help='which agent type to use (deepq,'\n",
    "    #                                                                             'olson, acer)')\n",
    "    # elif PDCF_config.CF_method == \"Olson\":\n",
    "    #     parser.add_argument('--agent_type', type=str, default=\"olson\", help='which agent type to use (deepq,'\n",
    "    #                                                                             'olson, acer)')\n",
    "    # else:\n",
    "    parser.add_argument('--agent_type', type=str, default=PDCF_config.CF_method, help='which agent type to use (deepq,'\n",
    "                                                                                'olson, acer)')\n",
    "        \n",
    "    parser.add_argument('--ablate_agent', type=bool, default=False, help='whether to ablate the laser canon before'\n",
    "                                                                         'inputting a frame to the agent')\n",
    "    parser.add_argument('--agent_algo', type=str, default=PDCF_config.teacher_alg, help='DQN, PPO, A2C')\n",
    "    parser.add_argument('--saliency_method', type=str, default=PDCF_config.saliency_method, \\\n",
    "        help='HiResCAM, AblationCAM, ScoreCAM, LayerCAM, FullGradDeep, FeatureFactorization')\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args\n",
    "\n",
    "args = get_PDCF_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main loop\n",
    "- put the environments that need to be run in the first for loop, e,g. [\"highway\", \"pong\"]\n",
    "- put the DRL models on the second for loop, e,g. [\"DQN\", \"PPO\"]\n",
    "- for the first run only uncomment the \"train_teacher\" function to create the needed DRL.\n",
    "- for the first run only uncomment the \"create_img_dataset\" function to create the needed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samadi_a@WMGDS.WMG.WARWICK.AC.UK/anaconda3/envs/PDCF1/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: an integer is required (got type bytes)\n",
      "  warnings.warn(\n",
      "/home/samadi_a@WMGDS.WMG.WARWICK.AC.UK/anaconda3/envs/PDCF1/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n",
      "/home/samadi_a@WMGDS.WMG.WARWICK.AC.UK/anaconda3/envs/PDCF1/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:752: UserWarning: You are probably loading a model saved with SB3 < 1.7.0, we deactivated exact_match so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). Original error: Error(s) in loading state_dict for ActorCriticCnnPolicy:\n",
      "\tMissing key(s) in state_dict: \"pi_features_extractor.cnn.0.weight\", \"pi_features_extractor.cnn.0.bias\", \"pi_features_extractor.cnn.2.weight\", \"pi_features_extractor.cnn.2.bias\", \"pi_features_extractor.cnn.4.weight\", \"pi_features_extractor.cnn.4.bias\", \"pi_features_extractor.linear.0.weight\", \"pi_features_extractor.linear.0.bias\", \"vf_features_extractor.cnn.0.weight\", \"vf_features_extractor.cnn.0.bias\", \"vf_features_extractor.cnn.2.weight\", \"vf_features_extractor.cnn.2.bias\", \"vf_features_extractor.cnn.4.weight\", \"vf_features_extractor.cnn.4.bias\", \"vf_features_extractor.linear.0.weight\", \"vf_features_extractor.linear.0.bias\".  \n",
      "Note: the model should still work fine, this only a warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in dataset:35784\n",
      "Namespace(ablate_agent=False, agent_algo='A2C', agent_path=None, agent_type='SAFE_RL_attGAN', batch_size=8, beta1=0.5, beta2=0.999, c2_dim=6, c_dim=6, celeba_crop_size=178, counter_mode='cross_entropy', d_conv_dim=64, d_lambda_cls=1, d_lr=0.0001, d_repeat_num=6, dataset='pong', g_conv_dim=64, g_lambda_cls=1, g_loss_cls_of_d=False, g_lr=0.0001, g_repeat_num=6, image_channels=3, image_size=84, lambda_counter=0, lambda_gp=10, lambda_rec_sal=10, lambda_rec_x=10, lambda_sal_fuse=5, log_dir='baseline/SAFE_RL_attGAN/pong/A2C/logs', log_step=10, lr_update_step=1000, metrics=['KID', 'FID', 'LPIPS', 'IS', 'sparsity', 'mean_dis', 'validity'], mode='train', model_save_dir='baseline/SAFE_RL_attGAN/pong/A2C/models', model_save_step=20000, n_critic=5, num_iters=400000, num_iters_decay=100000, num_workers=60, rafd_crop_size=256, result_dir='baseline/SAFE_RL_attGAN/pong/A2C/results', resume_iters=None, saliency_method='EigenCAM', sample_dir='baseline/SAFE_RL_attGAN/pong/A2C/samples', sample_step=1000, selective_counter=False, test_iters=200000)\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(14, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(64, 13, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "  )\n",
      ")\n",
      "G\n",
      "The number of parameters: 8480704\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(7, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (11): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(2048, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n",
      "D\n",
      "The number of parameters: 44737472\n",
      "Start models...\n",
      "Elapsed [0:00:02], Iteration [10/400000], D/loss_real: -2.7136, D/loss_fake: -1.0648, D/loss_cls: 1.0574, D/loss_gp: 0.6849, G/loss_fake: 2.7501, G/loss_rec_x: 0.3666, G/loss_rec_obs: 0.2013, G/loss_rec_sal: 0.3546, G/loss_sal_fuse: 0.3158, G/loss_cls: 3.9297, G/loss_counter: 1.5436\n",
      "Elapsed [0:00:03], Iteration [20/400000], D/loss_real: -10.8062, D/loss_fake: -8.6746, D/loss_cls: 3.0178, D/loss_gp: 0.4021, G/loss_fake: 7.4386, G/loss_rec_x: 0.2365, G/loss_rec_obs: 0.1801, G/loss_rec_sal: 0.2899, G/loss_sal_fuse: 0.2308, G/loss_cls: 3.3446, G/loss_counter: 1.5436\n",
      "Elapsed [0:00:04], Iteration [30/400000], D/loss_real: -17.4968, D/loss_fake: 8.1452, D/loss_cls: 3.2211, D/loss_gp: 0.1140, G/loss_fake: 15.7502, G/loss_rec_x: 0.1500, G/loss_rec_obs: 0.1354, G/loss_rec_sal: 0.2876, G/loss_sal_fuse: 0.1619, G/loss_cls: 5.4163, G/loss_counter: 1.7936\n",
      "Elapsed [0:00:05], Iteration [40/400000], D/loss_real: -3.8640, D/loss_fake: -3.3796, D/loss_cls: 1.6056, D/loss_gp: 0.0253, G/loss_fake: 4.3361, G/loss_rec_x: 0.1306, G/loss_rec_obs: 0.1123, G/loss_rec_sal: 0.2649, G/loss_sal_fuse: 0.1299, G/loss_cls: 2.9689, G/loss_counter: 1.4186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     starGAN_config \u001b[38;5;241m=\u001b[39m get_starGAN_config(PDCF_config\u001b[38;5;241m=\u001b[39margs) \n\u001b[1;32m     48\u001b[0m     data_loader \u001b[38;5;241m=\u001b[39m get_loader(PDCF_config\u001b[38;5;241m=\u001b[39margs, starGAN_config\u001b[38;5;241m=\u001b[39mstarGAN_config, mode\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m---> 49\u001b[0m     \u001b[43mbasemodels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstarGAN_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarGAN_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPDCF_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(args\u001b[38;5;241m.\u001b[39mCF_method\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOlson\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     52\u001b[0m     Olson_config \u001b[38;5;241m=\u001b[39m get_Olson_config(PDCF_config\u001b[38;5;241m=\u001b[39margs)\n",
      "File \u001b[0;32m~/Desktop/samir/chapter 1/CF-teacher-student/src/star_gan/main.py:63\u001b[0m, in \u001b[0;36mbasemodels\u001b[0;34m(starGAN_config, PDCF_config, data_loader, teacher_model, Olson_config)\u001b[0m\n\u001b[1;32m     60\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(data_loader, starGAN_config, PDCF_config, teacher_model)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PDCF_config\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m PDCF_config\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFID\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKID\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Desktop/samir/chapter 1/CF-teacher-student/src/star_gan/solver.py:452\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Logging.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m loss \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 452\u001b[0m loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD/loss_real\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43md_loss_real\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD/loss_fake\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m d_loss_fake\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    454\u001b[0m loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD/loss_cls\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m d_loss_cls\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for env_name in [\"pong\", \"highway\", \"roundabout\"]:\n",
    "    if env_name == \"highway\":\n",
    "        args.env ='highway'\n",
    "        args.env_name = 'highway-fast-v0'\n",
    "        args.obs_size = (128, 512) \n",
    "        args.image_size = (128, 512) \n",
    "        args.centering_position = [0.2, 0.5] \n",
    "    elif env_name == \"roundabout\":\n",
    "        args.env ='roundabout'\n",
    "        args.env_name = 'roundabout-v0'\n",
    "        args.obs_size = (448,448)\n",
    "        args.image_size = (448,448)\n",
    "        args.centering_position = [0.5, 0.85]\n",
    "    elif env_name == \"pong\":\n",
    "        args.env ='pong'\n",
    "        args.env_name = 'PongNoFrameskip-v4'\n",
    "        args.obs_size = (84,84)\n",
    "        args.image_size = (84,84)\n",
    "        args.centering_position = [0.5, 0.85]\n",
    "        args.num_Of_attributes=4\n",
    "        args.num_of_actions=6\n",
    "    \n",
    "    for DRL_agent in [\"A2C\", \"PPO\", \"DQN\"]: #\"PPO\", 'DQN', 'A2C',\n",
    "        args.teacher_alg = DRL_agent\n",
    "        if env_name in [\"pong\"]:\n",
    "            # teacher_model = pong_pkg.train_teacher(args)\n",
    "            teacher_model = pong_pkg.load_teacher(args)\n",
    "            # pong_pkg.create_img_dataset(args, teacher_model)\n",
    "        else:\n",
    "            # teacher_model = highway_pkg.train_teacher(args)\n",
    "            teacher_model = highway_pkg.load_teacher(args)\n",
    "            highway_pkg.teacher_model_play(teacher_model=teacher_model, config=args)\n",
    "            # highway_pkg.create_img_dataset(args, teacher_model)\n",
    "    \n",
    "        if(args.wandb_log):\n",
    "            starGAN_config = get_starGAN_config(PDCF_config=args)\n",
    "            wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=\"SAFE_RL\",\n",
    "            entity='amirsamadi',\n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "            \"PDCF_config\": args,\n",
    "            \"starGAN_config\": starGAN_config,})\n",
    "\n",
    "        if(args.CF_method in [\"SAFE_RL_starGAN\", \"SAFE_RL_attGAN\"]):\n",
    "            starGAN_config = get_starGAN_config(PDCF_config=args) \n",
    "            data_loader = get_loader(PDCF_config=args, starGAN_config=starGAN_config, mode=args.mode)\n",
    "            basemodels(starGAN_config=starGAN_config, PDCF_config=args, data_loader=data_loader, teacher_model=teacher_model)\n",
    "\n",
    "        elif(args.CF_method==\"Olson\"):\n",
    "            Olson_config = get_Olson_config(PDCF_config=args)\n",
    "            starGAN_config = get_starGAN_config(PDCF_config=args)\n",
    "            data_loader = get_loader(PDCF_config=args, starGAN_config=starGAN_config, mode=args.mode)\n",
    "            basemodels(starGAN_config=starGAN_config, PDCF_config=args, data_loader=data_loader, teacher_model=teacher_model, Olson_config=Olson_config)\n",
    "        \n",
    "        elif(args.CF_method==\"GANterfactual\"):\n",
    "            starGAN_config = get_starGAN_config(PDCF_config=args)\n",
    "            data_loader = get_loader(PDCF_config=args, starGAN_config=starGAN_config, mode=args.mode)\n",
    "            basemodels(starGAN_config=starGAN_config, PDCF_config=args, data_loader=data_loader, teacher_model=teacher_model)\n",
    "        \n",
    "        else:\n",
    "            raise(\"this CF method is not implemented yet!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
